{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'speech-based-classification-layer-10/train.csv'\n",
    "valid_path = 'speech-based-classification-layer-10/valid.csv'\n",
    "test_path = 'speech-based-classification-layer-10/test.csv'\n",
    "train = pd.read_csv(train_path)\n",
    "valid = pd.read_csv(valid_path)\n",
    "test = pd.read_csv(test_path)\n",
    "original_train = train.copy()\n",
    "original_valid = train.copy()\n",
    "original_test = test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Imputing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature_1        0\n",
       "feature_2        0\n",
       "feature_3        0\n",
       "feature_4        0\n",
       "feature_5        0\n",
       "              ... \n",
       "feature_768      0\n",
       "label_1          0\n",
       "label_2        480\n",
       "label_3          0\n",
       "label_4          0\n",
       "Length: 772, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_763</th>\n",
       "      <th>feature_764</th>\n",
       "      <th>feature_765</th>\n",
       "      <th>feature_766</th>\n",
       "      <th>feature_767</th>\n",
       "      <th>feature_768</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.027083</td>\n",
       "      <td>0.072947</td>\n",
       "      <td>-0.093659</td>\n",
       "      <td>0.053418</td>\n",
       "      <td>-0.085516</td>\n",
       "      <td>-0.102610</td>\n",
       "      <td>-0.021217</td>\n",
       "      <td>0.016162</td>\n",
       "      <td>-0.184269</td>\n",
       "      <td>0.110335</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.183643</td>\n",
       "      <td>0.091299</td>\n",
       "      <td>-0.037097</td>\n",
       "      <td>0.042607</td>\n",
       "      <td>-0.034361</td>\n",
       "      <td>-0.013748</td>\n",
       "      <td>45</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.070195</td>\n",
       "      <td>0.228641</td>\n",
       "      <td>-0.132860</td>\n",
       "      <td>-0.077761</td>\n",
       "      <td>-0.054993</td>\n",
       "      <td>-0.210365</td>\n",
       "      <td>0.127747</td>\n",
       "      <td>-0.132385</td>\n",
       "      <td>-0.161366</td>\n",
       "      <td>0.172764</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.123668</td>\n",
       "      <td>0.029626</td>\n",
       "      <td>-0.027345</td>\n",
       "      <td>0.055223</td>\n",
       "      <td>-0.179725</td>\n",
       "      <td>0.136841</td>\n",
       "      <td>45</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.164312</td>\n",
       "      <td>0.052808</td>\n",
       "      <td>-0.058510</td>\n",
       "      <td>0.104724</td>\n",
       "      <td>-0.025886</td>\n",
       "      <td>-0.101427</td>\n",
       "      <td>-0.047177</td>\n",
       "      <td>0.091298</td>\n",
       "      <td>-0.094569</td>\n",
       "      <td>0.088062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075410</td>\n",
       "      <td>0.070125</td>\n",
       "      <td>0.043022</td>\n",
       "      <td>0.012972</td>\n",
       "      <td>-0.028920</td>\n",
       "      <td>0.096725</td>\n",
       "      <td>45</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.029730</td>\n",
       "      <td>0.113737</td>\n",
       "      <td>0.061113</td>\n",
       "      <td>-0.099329</td>\n",
       "      <td>-0.111600</td>\n",
       "      <td>-0.245942</td>\n",
       "      <td>0.086520</td>\n",
       "      <td>0.071996</td>\n",
       "      <td>0.028319</td>\n",
       "      <td>0.207910</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062511</td>\n",
       "      <td>-0.226912</td>\n",
       "      <td>-0.046011</td>\n",
       "      <td>0.011282</td>\n",
       "      <td>-0.095167</td>\n",
       "      <td>0.039979</td>\n",
       "      <td>45</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.031364</td>\n",
       "      <td>0.142409</td>\n",
       "      <td>-0.160743</td>\n",
       "      <td>-0.076594</td>\n",
       "      <td>-0.062412</td>\n",
       "      <td>-0.264732</td>\n",
       "      <td>0.079197</td>\n",
       "      <td>0.026060</td>\n",
       "      <td>-0.217023</td>\n",
       "      <td>0.084656</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193882</td>\n",
       "      <td>0.107297</td>\n",
       "      <td>-0.042355</td>\n",
       "      <td>0.046763</td>\n",
       "      <td>-0.192469</td>\n",
       "      <td>0.006463</td>\n",
       "      <td>45</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28515</th>\n",
       "      <td>-0.035973</td>\n",
       "      <td>0.072715</td>\n",
       "      <td>-0.270282</td>\n",
       "      <td>0.091208</td>\n",
       "      <td>-0.191320</td>\n",
       "      <td>-0.216611</td>\n",
       "      <td>0.021817</td>\n",
       "      <td>0.023942</td>\n",
       "      <td>0.013130</td>\n",
       "      <td>0.092222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186235</td>\n",
       "      <td>-0.071871</td>\n",
       "      <td>0.134874</td>\n",
       "      <td>-0.046534</td>\n",
       "      <td>-0.049209</td>\n",
       "      <td>0.148759</td>\n",
       "      <td>39</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28516</th>\n",
       "      <td>0.069470</td>\n",
       "      <td>0.087150</td>\n",
       "      <td>-0.020916</td>\n",
       "      <td>0.015028</td>\n",
       "      <td>0.011037</td>\n",
       "      <td>-0.119964</td>\n",
       "      <td>0.064952</td>\n",
       "      <td>-0.029355</td>\n",
       "      <td>-0.040469</td>\n",
       "      <td>0.037754</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064835</td>\n",
       "      <td>0.015068</td>\n",
       "      <td>-0.055220</td>\n",
       "      <td>-0.039519</td>\n",
       "      <td>-0.006166</td>\n",
       "      <td>-0.014526</td>\n",
       "      <td>39</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28517</th>\n",
       "      <td>0.131181</td>\n",
       "      <td>0.151207</td>\n",
       "      <td>-0.054255</td>\n",
       "      <td>0.175156</td>\n",
       "      <td>0.054449</td>\n",
       "      <td>-0.178458</td>\n",
       "      <td>-0.031890</td>\n",
       "      <td>-0.071265</td>\n",
       "      <td>-0.031498</td>\n",
       "      <td>0.016970</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054301</td>\n",
       "      <td>0.016186</td>\n",
       "      <td>-0.051473</td>\n",
       "      <td>0.055153</td>\n",
       "      <td>-0.106647</td>\n",
       "      <td>-0.011164</td>\n",
       "      <td>39</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28518</th>\n",
       "      <td>0.031407</td>\n",
       "      <td>0.095880</td>\n",
       "      <td>-0.040718</td>\n",
       "      <td>0.093964</td>\n",
       "      <td>-0.046821</td>\n",
       "      <td>-0.085009</td>\n",
       "      <td>0.020143</td>\n",
       "      <td>0.047911</td>\n",
       "      <td>-0.145057</td>\n",
       "      <td>0.021328</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115632</td>\n",
       "      <td>0.056439</td>\n",
       "      <td>-0.033905</td>\n",
       "      <td>0.031283</td>\n",
       "      <td>-0.095751</td>\n",
       "      <td>0.035147</td>\n",
       "      <td>39</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28519</th>\n",
       "      <td>0.062807</td>\n",
       "      <td>0.148621</td>\n",
       "      <td>-0.112186</td>\n",
       "      <td>0.147993</td>\n",
       "      <td>-0.021369</td>\n",
       "      <td>-0.167056</td>\n",
       "      <td>0.001904</td>\n",
       "      <td>-0.081141</td>\n",
       "      <td>-0.035111</td>\n",
       "      <td>-0.006730</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.124477</td>\n",
       "      <td>0.049659</td>\n",
       "      <td>-0.132178</td>\n",
       "      <td>0.074743</td>\n",
       "      <td>-0.208911</td>\n",
       "      <td>-0.089137</td>\n",
       "      <td>39</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28520 rows × 772 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0      -0.027083   0.072947  -0.093659   0.053418  -0.085516  -0.102610   \n",
       "1       0.070195   0.228641  -0.132860  -0.077761  -0.054993  -0.210365   \n",
       "2       0.164312   0.052808  -0.058510   0.104724  -0.025886  -0.101427   \n",
       "3       0.029730   0.113737   0.061113  -0.099329  -0.111600  -0.245942   \n",
       "4       0.031364   0.142409  -0.160743  -0.076594  -0.062412  -0.264732   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "28515  -0.035973   0.072715  -0.270282   0.091208  -0.191320  -0.216611   \n",
       "28516   0.069470   0.087150  -0.020916   0.015028   0.011037  -0.119964   \n",
       "28517   0.131181   0.151207  -0.054255   0.175156   0.054449  -0.178458   \n",
       "28518   0.031407   0.095880  -0.040718   0.093964  -0.046821  -0.085009   \n",
       "28519   0.062807   0.148621  -0.112186   0.147993  -0.021369  -0.167056   \n",
       "\n",
       "       feature_7  feature_8  feature_9  feature_10  ...  feature_763  \\\n",
       "0      -0.021217   0.016162  -0.184269    0.110335  ...    -0.183643   \n",
       "1       0.127747  -0.132385  -0.161366    0.172764  ...    -0.123668   \n",
       "2      -0.047177   0.091298  -0.094569    0.088062  ...     0.075410   \n",
       "3       0.086520   0.071996   0.028319    0.207910  ...    -0.062511   \n",
       "4       0.079197   0.026060  -0.217023    0.084656  ...    -0.193882   \n",
       "...          ...        ...        ...         ...  ...          ...   \n",
       "28515   0.021817   0.023942   0.013130    0.092222  ...     0.186235   \n",
       "28516   0.064952  -0.029355  -0.040469    0.037754  ...    -0.064835   \n",
       "28517  -0.031890  -0.071265  -0.031498    0.016970  ...    -0.054301   \n",
       "28518   0.020143   0.047911  -0.145057    0.021328  ...    -0.115632   \n",
       "28519   0.001904  -0.081141  -0.035111   -0.006730  ...    -0.124477   \n",
       "\n",
       "       feature_764  feature_765  feature_766  feature_767  feature_768  \\\n",
       "0         0.091299    -0.037097     0.042607    -0.034361    -0.013748   \n",
       "1         0.029626    -0.027345     0.055223    -0.179725     0.136841   \n",
       "2         0.070125     0.043022     0.012972    -0.028920     0.096725   \n",
       "3        -0.226912    -0.046011     0.011282    -0.095167     0.039979   \n",
       "4         0.107297    -0.042355     0.046763    -0.192469     0.006463   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "28515    -0.071871     0.134874    -0.046534    -0.049209     0.148759   \n",
       "28516     0.015068    -0.055220    -0.039519    -0.006166    -0.014526   \n",
       "28517     0.016186    -0.051473     0.055153    -0.106647    -0.011164   \n",
       "28518     0.056439    -0.033905     0.031283    -0.095751     0.035147   \n",
       "28519     0.049659    -0.132178     0.074743    -0.208911    -0.089137   \n",
       "\n",
       "       label_1  label_2  label_3  label_4  \n",
       "0           45       27        1        6  \n",
       "1           45       27        1        6  \n",
       "2           45       27        1        6  \n",
       "3           45       27        1        6  \n",
       "4           45       27        1        6  \n",
       "...        ...      ...      ...      ...  \n",
       "28515       39       29        1        6  \n",
       "28516       39       29        1        6  \n",
       "28517       39       29        1        6  \n",
       "28518       39       29        1        6  \n",
       "28519       39       29        1        6  \n",
       "\n",
       "[28520 rows x 772 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_age = int(train['label_2'].mean())\n",
    "train['label_2'].fillna(mean_age, inplace=True)\n",
    "train['label_2'] = train['label_2'].astype(int)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature_1       0\n",
       "feature_2       0\n",
       "feature_3       0\n",
       "feature_4       0\n",
       "feature_5       0\n",
       "               ..\n",
       "feature_768     0\n",
       "label_1         0\n",
       "label_2        14\n",
       "label_3         0\n",
       "label_4         0\n",
       "Length: 772, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_763</th>\n",
       "      <th>feature_764</th>\n",
       "      <th>feature_765</th>\n",
       "      <th>feature_766</th>\n",
       "      <th>feature_767</th>\n",
       "      <th>feature_768</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.089057</td>\n",
       "      <td>0.072797</td>\n",
       "      <td>-0.076338</td>\n",
       "      <td>0.115915</td>\n",
       "      <td>-0.019868</td>\n",
       "      <td>-0.081843</td>\n",
       "      <td>-0.036667</td>\n",
       "      <td>0.006569</td>\n",
       "      <td>-0.077875</td>\n",
       "      <td>-0.014323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019353</td>\n",
       "      <td>0.162292</td>\n",
       "      <td>0.056965</td>\n",
       "      <td>-0.004469</td>\n",
       "      <td>-0.040084</td>\n",
       "      <td>0.072282</td>\n",
       "      <td>45</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.023128</td>\n",
       "      <td>0.081442</td>\n",
       "      <td>-0.091982</td>\n",
       "      <td>0.021188</td>\n",
       "      <td>-0.062825</td>\n",
       "      <td>-0.080544</td>\n",
       "      <td>0.015052</td>\n",
       "      <td>-0.067189</td>\n",
       "      <td>-0.157901</td>\n",
       "      <td>0.062454</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.166827</td>\n",
       "      <td>0.201730</td>\n",
       "      <td>-0.062621</td>\n",
       "      <td>0.058383</td>\n",
       "      <td>-0.075039</td>\n",
       "      <td>0.023428</td>\n",
       "      <td>45</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.024480</td>\n",
       "      <td>0.114591</td>\n",
       "      <td>0.011653</td>\n",
       "      <td>-0.036223</td>\n",
       "      <td>-0.033679</td>\n",
       "      <td>-0.157527</td>\n",
       "      <td>0.006977</td>\n",
       "      <td>-0.009106</td>\n",
       "      <td>0.064919</td>\n",
       "      <td>0.052810</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050036</td>\n",
       "      <td>0.003152</td>\n",
       "      <td>-0.015791</td>\n",
       "      <td>-0.003751</td>\n",
       "      <td>-0.080954</td>\n",
       "      <td>-0.008283</td>\n",
       "      <td>45</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016545</td>\n",
       "      <td>0.076105</td>\n",
       "      <td>-0.080515</td>\n",
       "      <td>0.052122</td>\n",
       "      <td>-0.009976</td>\n",
       "      <td>-0.055965</td>\n",
       "      <td>0.005661</td>\n",
       "      <td>0.081433</td>\n",
       "      <td>-0.073674</td>\n",
       "      <td>-0.021476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068674</td>\n",
       "      <td>0.038822</td>\n",
       "      <td>0.062544</td>\n",
       "      <td>-0.039516</td>\n",
       "      <td>-0.056153</td>\n",
       "      <td>-0.041301</td>\n",
       "      <td>45</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008559</td>\n",
       "      <td>0.036037</td>\n",
       "      <td>-0.043777</td>\n",
       "      <td>0.050584</td>\n",
       "      <td>-0.071815</td>\n",
       "      <td>-0.187329</td>\n",
       "      <td>0.001175</td>\n",
       "      <td>-0.059212</td>\n",
       "      <td>-0.062420</td>\n",
       "      <td>-0.007780</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128719</td>\n",
       "      <td>0.041103</td>\n",
       "      <td>0.089034</td>\n",
       "      <td>0.033583</td>\n",
       "      <td>-0.151146</td>\n",
       "      <td>-0.064672</td>\n",
       "      <td>45</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>0.137915</td>\n",
       "      <td>0.018654</td>\n",
       "      <td>-0.037206</td>\n",
       "      <td>0.129737</td>\n",
       "      <td>-0.050488</td>\n",
       "      <td>-0.162754</td>\n",
       "      <td>-0.025517</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>-0.070894</td>\n",
       "      <td>0.109513</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.205148</td>\n",
       "      <td>0.047071</td>\n",
       "      <td>-0.071692</td>\n",
       "      <td>0.109726</td>\n",
       "      <td>-0.073694</td>\n",
       "      <td>-0.057727</td>\n",
       "      <td>39</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>0.006322</td>\n",
       "      <td>0.089902</td>\n",
       "      <td>-0.107340</td>\n",
       "      <td>0.062628</td>\n",
       "      <td>-0.107365</td>\n",
       "      <td>0.002409</td>\n",
       "      <td>-0.008505</td>\n",
       "      <td>0.113627</td>\n",
       "      <td>-0.120738</td>\n",
       "      <td>0.064056</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052288</td>\n",
       "      <td>0.039313</td>\n",
       "      <td>-0.085648</td>\n",
       "      <td>-0.079630</td>\n",
       "      <td>-0.066545</td>\n",
       "      <td>-0.163933</td>\n",
       "      <td>39</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>0.036668</td>\n",
       "      <td>0.125310</td>\n",
       "      <td>-0.055670</td>\n",
       "      <td>0.095170</td>\n",
       "      <td>-0.023049</td>\n",
       "      <td>-0.177663</td>\n",
       "      <td>-0.010594</td>\n",
       "      <td>-0.025151</td>\n",
       "      <td>-0.022994</td>\n",
       "      <td>0.112005</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.203588</td>\n",
       "      <td>0.025482</td>\n",
       "      <td>-0.100621</td>\n",
       "      <td>0.158005</td>\n",
       "      <td>-0.093643</td>\n",
       "      <td>-0.065391</td>\n",
       "      <td>39</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>0.108926</td>\n",
       "      <td>0.144031</td>\n",
       "      <td>-0.039965</td>\n",
       "      <td>0.168810</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>-0.109862</td>\n",
       "      <td>-0.004499</td>\n",
       "      <td>-0.051219</td>\n",
       "      <td>-0.063053</td>\n",
       "      <td>-0.025315</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061261</td>\n",
       "      <td>0.057384</td>\n",
       "      <td>0.013137</td>\n",
       "      <td>0.054172</td>\n",
       "      <td>-0.044807</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>39</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>0.065116</td>\n",
       "      <td>0.123392</td>\n",
       "      <td>-0.061682</td>\n",
       "      <td>0.072600</td>\n",
       "      <td>-0.033054</td>\n",
       "      <td>-0.111412</td>\n",
       "      <td>0.006921</td>\n",
       "      <td>0.057283</td>\n",
       "      <td>-0.057980</td>\n",
       "      <td>0.025920</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.088550</td>\n",
       "      <td>0.144103</td>\n",
       "      <td>-0.056721</td>\n",
       "      <td>0.023952</td>\n",
       "      <td>-0.059126</td>\n",
       "      <td>0.065241</td>\n",
       "      <td>39</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750 rows × 772 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0     0.089057   0.072797  -0.076338   0.115915  -0.019868  -0.081843   \n",
       "1     0.023128   0.081442  -0.091982   0.021188  -0.062825  -0.080544   \n",
       "2    -0.024480   0.114591   0.011653  -0.036223  -0.033679  -0.157527   \n",
       "3     0.016545   0.076105  -0.080515   0.052122  -0.009976  -0.055965   \n",
       "4     0.008559   0.036037  -0.043777   0.050584  -0.071815  -0.187329   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "745   0.137915   0.018654  -0.037206   0.129737  -0.050488  -0.162754   \n",
       "746   0.006322   0.089902  -0.107340   0.062628  -0.107365   0.002409   \n",
       "747   0.036668   0.125310  -0.055670   0.095170  -0.023049  -0.177663   \n",
       "748   0.108926   0.144031  -0.039965   0.168810   0.000203  -0.109862   \n",
       "749   0.065116   0.123392  -0.061682   0.072600  -0.033054  -0.111412   \n",
       "\n",
       "     feature_7  feature_8  feature_9  feature_10  ...  feature_763  \\\n",
       "0    -0.036667   0.006569  -0.077875   -0.014323  ...     0.019353   \n",
       "1     0.015052  -0.067189  -0.157901    0.062454  ...    -0.166827   \n",
       "2     0.006977  -0.009106   0.064919    0.052810  ...    -0.050036   \n",
       "3     0.005661   0.081433  -0.073674   -0.021476  ...     0.068674   \n",
       "4     0.001175  -0.059212  -0.062420   -0.007780  ...    -0.128719   \n",
       "..         ...        ...        ...         ...  ...          ...   \n",
       "745  -0.025517   0.006736  -0.070894    0.109513  ...    -0.205148   \n",
       "746  -0.008505   0.113627  -0.120738    0.064056  ...    -0.052288   \n",
       "747  -0.010594  -0.025151  -0.022994    0.112005  ...    -0.203588   \n",
       "748  -0.004499  -0.051219  -0.063053   -0.025315  ...    -0.061261   \n",
       "749   0.006921   0.057283  -0.057980    0.025920  ...    -0.088550   \n",
       "\n",
       "     feature_764  feature_765  feature_766  feature_767  feature_768  label_1  \\\n",
       "0       0.162292     0.056965    -0.004469    -0.040084     0.072282       45   \n",
       "1       0.201730    -0.062621     0.058383    -0.075039     0.023428       45   \n",
       "2       0.003152    -0.015791    -0.003751    -0.080954    -0.008283       45   \n",
       "3       0.038822     0.062544    -0.039516    -0.056153    -0.041301       45   \n",
       "4       0.041103     0.089034     0.033583    -0.151146    -0.064672       45   \n",
       "..           ...          ...          ...          ...          ...      ...   \n",
       "745     0.047071    -0.071692     0.109726    -0.073694    -0.057727       39   \n",
       "746     0.039313    -0.085648    -0.079630    -0.066545    -0.163933       39   \n",
       "747     0.025482    -0.100621     0.158005    -0.093643    -0.065391       39   \n",
       "748     0.057384     0.013137     0.054172    -0.044807     0.000401       39   \n",
       "749     0.144103    -0.056721     0.023952    -0.059126     0.065241       39   \n",
       "\n",
       "     label_2  label_3  label_4  \n",
       "0         27        1        6  \n",
       "1         27        1        6  \n",
       "2         27        1        6  \n",
       "3         27        1        6  \n",
       "4         27        1        6  \n",
       "..       ...      ...      ...  \n",
       "745       29        1        6  \n",
       "746       29        1        6  \n",
       "747       29        1        6  \n",
       "748       29        1        6  \n",
       "749       29        1        6  \n",
       "\n",
       "[750 rows x 772 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_age = int(train['label_2'].mean())\n",
    "valid['label_2'].fillna(mean_age, inplace=True)\n",
    "valid['label_2'] = valid['label_2'].astype(int)\n",
    "valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train.iloc[:, :768]\n",
    "train_label_2 = train.iloc[:, 769]\n",
    "\n",
    "valid_features = valid.iloc[:, :768]\n",
    "valid_label_2 = valid.iloc[:, 769]\n",
    "\n",
    "test_features = test.iloc[:, :768]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class Distribution Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_counts = train_label_2.value_counts()\n",
    "plt.figure(figsize=(8, 6))\n",
    "class_counts.plot(kind='bar', color='skyblue')\n",
    "\n",
    "plt.xlabel('Class Label')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Class Distribution')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From SVM and Random Forest classifiers choosing the best classification model\n",
    "1. Stratified K Fold model is used for cross validation\n",
    "2. Default parameters of classifcation models are used\n",
    "3. Since classes are balanced accuracy score is used for the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Average Accuracy: 0.4167251051893408\n",
      "SVM - Average Accuracy: 0.5042426367461431\n",
      "Best Model: SVC\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "\n",
    "classifiers = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "}\n",
    "\n",
    "\n",
    "best_model = None\n",
    "best_accuracy = 0.0\n",
    "\n",
    "\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    total_accuracy = 0.0\n",
    "\n",
    "    for train_index, test_index in skf.split(train_features, train_label_2):\n",
    "        X_train, X_test = train_features.iloc[train_index], train_features.iloc[test_index]\n",
    "        y_train, y_test = train_label_2[train_index], train_label_2[test_index]\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        total_accuracy += accuracy\n",
    "\n",
    "    average_accuracy = total_accuracy / n_splits\n",
    "    print(f\"{name} - Average Accuracy: {average_accuracy}\")\n",
    "\n",
    "\n",
    "    if average_accuracy > best_accuracy:\n",
    "        best_model = clf\n",
    "        best_accuracy = average_accuracy\n",
    "\n",
    "print(f\"Best Model: {type(best_model).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA Transformation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def performPca(train_input, valid_input,test_input, n_components):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    train_reduced = pca.fit_transform(train_input)\n",
    "    valid_reduced = pca.transform(valid_input)\n",
    "    test_reduced = pca.transform(test_input)\n",
    "    train_reduced_df = pd.DataFrame(train_reduced, columns=[f\"new_feature_{i+1}\" for i in range(train_reduced.shape[1])])\n",
    "    valid_reduced_df = pd.DataFrame(valid_reduced, columns=[f\"new_feature_{i+1}\" for i in range(valid_reduced.shape[1])])\n",
    "    test_reduced_df = pd.DataFrame(test_reduced, columns=[f\"new_feature_{i+1}\" for i in range(test_reduced.shape[1])])\n",
    "\n",
    "\n",
    "    return train_reduced_df, valid_reduced_df,test_reduced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "transformer = RobustScaler()\n",
    "scaled_train_features = transformer.fit_transform(train_features)\n",
    "scaled_valid_features = transformer.fit_transform(valid_features)\n",
    "scaled_test_features = transformer.fit_transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reduced_df, valid_reduced_df,test_reduced_df = performPca(scaled_train_features, scaled_valid_features, scaled_test_features, 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9293333333333333\n"
     ]
    }
   ],
   "source": [
    "model = SVC()\n",
    "model.fit(train_reduced_df, train_label_2)\n",
    "y_pred = model.predict(valid_reduced_df)\n",
    "accuracy = accuracy_score(valid_label_2, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(test_reduced_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write to file\n",
    "test_pred_df = pd.DataFrame(test_pred, columns=['label_2'])\n",
    "test_pred_df.to_csv('predictions/label_2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
